{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd78b38d",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CompOmics/D012554A_2025/blob/main/notebooks/day_3/3.1b_Exercises_Histone_marks_dt.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367310b2",
   "metadata": {},
   "source": [
    "# 3.1 Exercises – Decision Trees, Bias-Variance & Ensemble Learning\n",
    "\n",
    "In the lecture notebook you applied decision trees, bagging, and random forests to classify gene expression from histone modifications. In these exercises you will apply those same techniques to the Breast Cancer Wisconsin dataset you already know from the logistic regression exercises — so you can directly compare decision-tree–based models with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61554f7",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 1 – Load the data and create a train/validation split\n",
    "\n",
    "1. Load the Breast Cancer dataset with `load_breast_cancer()`.\n",
    "2. Create a DataFrame for features and a Series for the target.\n",
    "3. Split into 80 % training / 20 % validation (`random_state=42`).\n",
    "4. Print the shape of both sets and the class distribution of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f3396",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 2 – Fit a decision tree with limited depth\n",
    "\n",
    "1. Create a `DecisionTreeClassifier` with `max_depth=3` and `random_state=42`.\n",
    "2. Fit it on the training data.\n",
    "3. Compute and print the accuracy and log-loss on both the training and validation sets.\n",
    "\n",
    "Hint: Use `predict` for accuracy and `predict_proba` for log-loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3ca671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e0f47a",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3 – Visualize the decision tree\n",
    "\n",
    "Use `sklearn.tree.plot_tree` to visualize the tree you just trained.\n",
    "\n",
    "Hint: Use `feature_names=data.feature_names`, `class_names=data.target_names`, `filled=True`, `rounded=True`.\n",
    "A large figure size (e.g. `figsize=(20, 10)`) will help readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc8304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976179ca",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 4 – Effect of `max_depth` (overfitting curve)\n",
    "\n",
    "1. Use `GridSearchCV` with `max_depth` values from 1 to 15 and `scoring='neg_log_loss'`.\n",
    "2. Use 5-fold CV and set `return_train_score=True`.\n",
    "3. Plot the mean training log-loss and mean validation log-loss vs `max_depth`.\n",
    "4. Print the best `max_depth`.\n",
    "\n",
    "At which depth does the model start overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850bf7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a8dfe",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2 – Understanding Bias & Variance\n",
    "\n",
    "In machine learning, prediction errors come from two main sources:\n",
    "\n",
    "Bias is the error from wrong assumptions. A model with high bias oversimplifies and misses patterns in the data. *Example*: a decision tree with `max_depth=1` can only make a single split — it cannot capture complex relationships.\n",
    "\n",
    "Variance is the error from sensitivity to which data we happen to train on. A model with high variance changes drastically when trained on different subsets. *Example*: a deep decision tree memorises the training data, so different training sets produce wildly different models.\n",
    "\n",
    "| | Low Variance | High Variance |\n",
    "|---|---|---|\n",
    "| Low Bias | ✅ Ideal model | ⚠️ Overfitting |\n",
    "| High Bias | ⚠️ Underfitting | ❌ Both problems |\n",
    "\n",
    "Key insight: Ensemble methods (bagging, random forests) reduce variance by averaging many high-variance models, giving us the best of both worlds: low bias and low variance.\n",
    "\n",
    "In the next exercises you will see this in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08282f6f",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 5 – Variance in action: 50 trees, 50 stories\n",
    "\n",
    "To see how much a single decision tree's predictions depend on the training data, we will:\n",
    "\n",
    "1. Create 50 bootstrap samples (sampling with replacement) from the training set.\n",
    "2. Train an unrestricted decision tree (`max_depth=None`) on each bootstrap sample.\n",
    "3. Record each tree's predicted P(benign) for every validation instance.\n",
    "\n",
    "Then analyse the results:\n",
    "- Compute the variance of predictions for each validation instance.\n",
    "- Compute the mean prediction (= a simple ensemble!).\n",
    "- Compare the log-loss of the mean prediction with the log-loss of a single tree.\n",
    "- Create two plots:\n",
    "  - *Left*: histogram of per-instance prediction variance.\n",
    "  - *Right*: scatter plot of individual tree predictions (faint) vs the ensemble average (red).\n",
    "\n",
    "The bootstrap loop is provided below — fill in the tree fitting and the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc214f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees to train on bootstrap samples\n",
    "n_models = 50\n",
    "\n",
    "# Array to store predicted P(benign) for each tree x each validation instance\n",
    "all_probs = np.zeros((n_models, len(val_X)))\n",
    "\n",
    "for i in range(n_models):\n",
    "    # Create a bootstrap sample (sampling WITH replacement)\n",
    "    rng = np.random.RandomState(i)\n",
    "    boot_idx = rng.choice(len(train_X), size=len(train_X), replace=True)\n",
    "    boot_X = train_X.iloc[boot_idx]\n",
    "    boot_y = train_y.iloc[boot_idx]\n",
    "\n",
    "    # YOUR CODE HERE:\n",
    "    # 1. Create and fit a DecisionTreeClassifier (no max_depth limit, random_state=i)\n",
    "    # 2. Store predicted P(benign) for all validation instances in all_probs[i]\n",
    "    #    Hint: dt.predict_proba(val_X)[:, 1]\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# 1. Compute the VARIANCE of predictions for each instance (across the 50 trees)\n",
    "# 2. Compute the MEAN prediction for each instance\n",
    "# 3. Print: average variance, log-loss of mean predictions, log-loss of a single tree\n",
    "# 4. Create a figure with two side-by-side subplots:\n",
    "#    Left:  histogram of per-instance variances\n",
    "#    Right: scatter of individual tree predictions (faint) vs ensemble average (red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6d6a54",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 6 – Following individual instances\n",
    "\n",
    "Pick three specific validation instances — one *easy* (low variance), one *hard* (high variance), and one *medium* — and create a histogram of the 50 predicted probabilities for each.\n",
    "\n",
    "Add vertical lines for the mean prediction (red) and the decision boundary at 0.5 (grey).\n",
    "\n",
    "The instance selection is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31acdb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select instances with different variance levels\n",
    "instance_variances = all_probs.var(axis=0)\n",
    "easy_idx = np.argmin(instance_variances)        # lowest variance\n",
    "hard_idx = np.argmax(instance_variances)        # highest variance\n",
    "medium_idx = np.argsort(instance_variances)[len(instance_variances) // 2]\n",
    "\n",
    "print(f\"Easy   (idx={easy_idx}): true={val_y.iloc[easy_idx]}, variance={instance_variances[easy_idx]:.4f}\")\n",
    "print(f\"Hard   (idx={hard_idx}): true={val_y.iloc[hard_idx]}, variance={instance_variances[hard_idx]:.4f}\")\n",
    "print(f\"Medium (idx={medium_idx}): true={val_y.iloc[medium_idx]}, variance={instance_variances[medium_idx]:.4f}\")\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# Create a figure with 3 subplots (1 row, 3 columns)\n",
    "# For each instance plot a HISTOGRAM of the 50 predicted probabilities\n",
    "# Add vertical lines for:\n",
    "#   - Mean prediction (red dashed)\n",
    "#   - Decision boundary at 0.5 (grey dotted)\n",
    "#\n",
    "# Hint: all_probs[:, easy_idx] gives the 50 predictions for the easy instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca724a",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 7 – The power of averaging: growing ensembles\n",
    "\n",
    "Now let's see how ensemble size affects prediction quality. Using the 50 trees you already trained:\n",
    "\n",
    "1. For each ensemble size in `[1, 2, 3, 5, 10, 25, 50]`, average the predictions of the first *N* trees.\n",
    "2. Compute the validation log-loss for each ensemble size.\n",
    "3. Also track how the prediction for each of the 3 tracked instances changes.\n",
    "\n",
    "Create two figures:\n",
    "- Figure 1: Log-loss vs ensemble size.\n",
    "- Figure 2: 3 subplots showing how each tracked instance’s averaged prediction converges as the ensemble grows. Add horizontal lines for the true label and the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_sizes = [1, 2, 3, 5, 10, 25, 50]\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# 1. For each size N, compute: avg_probs = all_probs[:N].mean(axis=0)\n",
    "# 2. Compute log_loss(val_y, avg_probs) and store it\n",
    "# 3. Record avg_probs[easy_idx], avg_probs[hard_idx], avg_probs[medium_idx]\n",
    "#\n",
    "# Figure 1: line plot of log-loss vs ensemble size\n",
    "# Figure 2: 3 subplots showing prediction vs ensemble size for each tracked instance\n",
    "#           Add horizontal lines for true label (green) and 0.5 (grey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19db293",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3 – Ensemble Learning with scikit-learn\n",
    "\n",
    "In the exercises above you built ensembles \"by hand\" by averaging individual trees. Scikit-learn provides two powerful ensemble classifiers that automate and improve on this idea:\n",
    "\n",
    "- `BaggingClassifier`: trains each tree on a different bootstrap sample (exactly what you did above, but optimised).\n",
    "- `RandomForestClassifier`: like bagging, but also randomly selects a *subset of features* at each split, further decorrelating the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778130ea",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8 – BaggingClassifier: effect of ensemble size\n",
    "\n",
    "1. Fit `BaggingClassifier` (with `DecisionTreeClassifier()` as the base estimator) for each value in `n_estimators = [1, 5, 10, 25, 50, 100, 200]`.\n",
    "2. Record validation accuracy and log-loss for each.\n",
    "3. Plot both metrics vs `n_estimators` (two subplots).\n",
    "\n",
    "At what point do diminishing returns set in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c0891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa92ee",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 9 – Random Forest & hyperparameter tuning\n",
    "\n",
    "1. Fit a `RandomForestClassifier` with default hyperparameters and print accuracy + log-loss.\n",
    "2. Use `GridSearchCV` to tune:\n",
    "   - `n_estimators`: [50, 100, 200]\n",
    "   - `max_depth`: [5, 10, None]\n",
    "   - `min_samples_leaf`: [1, 2, 4]\n",
    "3. Print the best hyperparameters and evaluate the best model on the validation set.\n",
    "4. Extract and plot the top 10 feature importances from the best model.\n",
    "\n",
    "Hint: Feature importances are in `best_model.feature_importances_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b3d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99fff40",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus – Model comparison\n",
    "\n",
    "Create a summary table comparing all the models you have trained:\n",
    "\n",
    "| Model | Val Accuracy | Val Log-Loss |\n",
    "|-------|-------------|-------------|\n",
    "| Single DT (max_depth=3) | ... | ... |\n",
    "| Single DT (best depth from GridSearchCV) | ... | ... |\n",
    "| Manual ensemble (50 bootstrapped trees) | ... | ... |\n",
    "| BaggingClassifier (best n_estimators) | ... | ... |\n",
    "| RandomForest (tuned) | ... | ... |\n",
    "\n",
    "Create a bar chart comparing the log-loss values.\n",
    "\n",
    "Which approach gives the best result? How does it compare to the logistic regression you trained in the 2.1 exercises?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d003f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
