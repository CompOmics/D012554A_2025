{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4eb04b1",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CompOmics/D012554A_2025/blob/main/notebooks/day_1/1.1b_Exercises_Linear_regression.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b0372",
   "metadata": {},
   "source": [
    "# 1.1 Exercises — Linear Regression\n",
    "\n",
    "In the lecture notebook you learned the fundamentals of linear regression using a diabetes dataset. In these exercises you will apply those same techniques to a new problem: predicting the fuel efficiency (miles per gallon) of automobiles from their technical specifications.\n",
    "\n",
    "The dataset comes from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/auto+mpg) and contains data for 392 cars. Each car is described by:\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **cylinders** | Number of cylinders |\n",
    "| **displacement** | Engine displacement (cubic inches) |\n",
    "| **horsepower** | Engine horsepower |\n",
    "| **weight** | Vehicle weight (lbs) |\n",
    "| **acceleration** | Time to accelerate from 0 to 60 mph (seconds) |\n",
    "| **model_year** | Model year (e.g. 70 = 1970) |\n",
    "| **origin** | Origin of car (usa, europe, japan) |\n",
    "\n",
    "The **target** variable is **mpg** (miles per gallon).\n",
    "\n",
    "Throughout these exercises you will:\n",
    "- Explore and visualize the dataset\n",
    "- Standardize features\n",
    "- Manually construct and evaluate linear models using $R^2$\n",
    "- Implement a cost function and gradient descent from scratch\n",
    "- Use scikit-learn for multi-feature linear regression\n",
    "- Evaluate generalization using a train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "146552cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3abbcb0",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 1 — Load and Explore the Data\n",
    "\n",
    "**Tasks:**\n",
    "1. Load the Auto MPG dataset from the URL provided below.\n",
    "2. Print the first 10 rows.\n",
    "3. How many cars and features are in the dataset?\n",
    "4. Use `.describe()` to compute summary statistics. What is the average fuel efficiency (mpg)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee7eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/mpg.csv\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "dataset = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8acfaa2",
   "metadata": {},
   "source": [
    "We will work only with the numeric columns. Run the cell below to drop the `name` column and any rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=['name']).dropna()\n",
    "\n",
    "# Convert origin from string to numeric (usa=1, europe=2, japan=3)\n",
    "origin_map = {'usa': 1, 'europe': 2, 'japan': 3}\n",
    "dataset['origin'] = dataset['origin'].map(origin_map)\n",
    "\n",
    "print(f\"Clean dataset shape: {dataset.shape}\")\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b834ce1",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 2 — Visualize Relationships\n",
    "\n",
    "Before building any model, visually inspect which features might be good predictors of **mpg**.\n",
    "\n",
    "**Tasks:**\n",
    "1. Create a scatter plot of **weight** (x-axis) vs **mpg** (y-axis).\n",
    "2. Create a scatter plot of **horsepower** (x-axis) vs **mpg** (y-axis).\n",
    "3. Create a scatter plot of **acceleration** (x-axis) vs **mpg** (y-axis).\n",
    "4. Which feature appears to have the strongest linear relationship with mpg? Is it positive or negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8287fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b10941",
   "metadata": {},
   "source": [
    "*Write your answer about which feature has the strongest linear relationship here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7328bd52",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3 — Standardize the Data\n",
    "\n",
    "Recall from the lecture that we should standardize features before fitting a linear model so that all features are on the same scale.\n",
    "\n",
    "**Tasks:**\n",
    "1. Create a `StandardScaler` for the feature **weight** and standardize it.\n",
    "2. Create a `StandardScaler` for the target **mpg** and standardize it.\n",
    "3. Verify that the standardized weight has mean $\\approx 0$ and standard deviation $\\approx 1$.\n",
    "4. Create a scatter plot of the standardized weight vs standardized mpg. Does the shape look different from Exercise 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d284faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scaler = StandardScaler()\n",
    "label_scaler = StandardScaler()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Fit and transform weight and mpg\n",
    "\n",
    "\n",
    "# Verify mean ≈ 0 and std ≈ 1\n",
    "\n",
    "\n",
    "# Scatter plot of standardized data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b4c5a",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 4 — Fit a Manual Linear Model\n",
    "\n",
    "Now let's manually pick parameters for a linear model $f(x) = ax + b$ and evaluate the fit.\n",
    "\n",
    "Since the data is standardized, we expect $b \\approx 0$. Set $b = 0$.\n",
    "\n",
    "**Tasks:**\n",
    "1. Looking at the scatter plot from Exercise 3, the relationship between weight and mpg is **negative** (heavier cars get fewer miles per gallon). Pick a negative value for $a$ that you think fits the data well.\n",
    "2. Plot your regression line on top of the standardized scatter plot.\n",
    "3. Compute $R^2$ manually using:\n",
    "\n",
    "   $$SS_{error} = \\sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}))^2, \\quad SS_{total} = \\sum_{i=1}^{n} (y^{(i)} - \\bar{y})^2, \\quad R^2 = 1 - \\frac{SS_{error}}{SS_{total}}$$\n",
    "\n",
    "4. Verify your result with `sklearn.metrics.r2_score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289a6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ...  # pick a negative value\n",
    "b = 0\n",
    "\n",
    "# Plot the data with your regression line\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R-squared manually\n",
    "# YOUR CODE HERE\n",
    "SS_error = ...\n",
    "SS_total = ...\n",
    "R_squared = ...\n",
    "\n",
    "print(f\"Manual R-squared = {R_squared}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21802603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify with sklearn\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab4a757",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 5 — Implement the Cost Function\n",
    "\n",
    "Recall the cost function:\n",
    "\n",
    "$$J(a, b) = \\frac{1}{2n} \\sum_{i=1}^{n} (f(x^{(i)}, (a,b)) - y^{(i)})^2$$\n",
    "\n",
    "**Tasks:**\n",
    "1. Implement the function `cost_function(a, b, X, y)` below.\n",
    "2. Compute $J$ for your value of $a$ from Exercise 4 (with $b = 0$).\n",
    "3. Also compute $J$ for $a = 0$ and $a = -1$. Which has the lowest cost?\n",
    "\n",
    "> **Warning:** Be careful with operator precedence! `1.0/2*n` evaluates as `(1.0/2) * n`, not `1.0 / (2*n)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(a, b, X, y):\n",
    "    # YOUR CODE HERE\n",
    "    ...\n",
    "\n",
    "# Test your function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3de7f",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 6 — Visualize the Cost Landscape\n",
    "\n",
    "**Tasks:**\n",
    "1. Compute the cost $J(a, 0)$ for values of $a$ ranging from $-2$ to $2$ in steps of $0.05$.\n",
    "2. Plot $a$ on the x-axis and $J$ on the y-axis.\n",
    "3. At approximately which value of $a$ is the cost minimized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "a_values = np.arange(-2, 2, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f11c49",
   "metadata": {},
   "source": [
    "*At which value of $a$ is the cost minimized?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a41b2c1",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 7 — Implement Gradient Descent\n",
    "\n",
    "Now implement the gradient descent algorithm to automatically find the optimal slope. We use a single feature ($\\theta_1$ only, with $\\theta_0 = 0$).\n",
    "\n",
    "Recall the stochastic gradient descent update rule for a randomly selected data point $i$:\n",
    "\n",
    "$$\\theta_1 := \\theta_1 - \\alpha \\cdot (f(x^{(i)}, \\theta) - y^{(i)}) \\cdot x_1^{(i)}$$\n",
    "\n",
    "**Tasks:**\n",
    "1. Complete the `linear_regression()` function below by filling in the missing steps.\n",
    "2. Run it on the standardized Auto MPG data (weight vs mpg) with `alpha=0.01` and `iterations=5000`.\n",
    "3. Print the learned $\\theta_1$ and the corresponding $R^2$.\n",
    "4. Plot the data with the fitted regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fefd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y, alpha, iterations):\n",
    "    \"\"\"Perform linear regression using stochastic gradient descent.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, feature values\n",
    "    y : array-like, target values\n",
    "    alpha : float, learning rate\n",
    "    iterations : int, number of update steps\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta1 : float, the learned slope parameter\n",
    "    \"\"\"\n",
    "    # Step 1: initialize theta1 (e.g. to 0 or a random value)\n",
    "    theta1 = ...\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # Step 2: pick a random data point index\n",
    "        idx = ...\n",
    "        \n",
    "        # Step 3: compute the prediction for this data point\n",
    "        predict = ...\n",
    "        \n",
    "        # Step 4: compute the error (prediction - actual)\n",
    "        error = ...\n",
    "        \n",
    "        # Step 5: update theta1 using the gradient descent rule\n",
    "        theta1 = ...\n",
    "    \n",
    "    return theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7f126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run gradient descent\n",
    "theta1 = linear_regression(dataset['weight'], dataset['mpg'], alpha=0.01, iterations=5000)\n",
    "\n",
    "print(f\"theta1 = {theta1}\")\n",
    "print(f\"R-squared = {metrics.r2_score(dataset['mpg'], theta1 * dataset['weight'])}\")\n",
    "\n",
    "# Plot the result\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981672f",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8 — Effect of the Learning Rate\n",
    "\n",
    "The learning rate $\\alpha$ controls the size of each update step.\n",
    "\n",
    "**Tasks:**\n",
    "1. Run `linear_regression()` for each of the following learning rates: `0.0001`, `0.001`, `0.01`, `0.1`, `1.0` (use 5000 iterations each).\n",
    "2. For each, print the final $\\theta_1$ and $R^2$.\n",
    "3. What happens when $\\alpha$ is too large? What happens when it is too small?\n",
    "\n",
    "> **Tip:** Run each setting a few times since stochastic gradient descent uses random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "for alpha in [0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
    "    pass  # replace with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89339575",
   "metadata": {},
   "source": [
    "*Write your observations about the effect of the learning rate here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96aca0d",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 9 — Multi-feature Regression with Scikit-learn\n",
    "\n",
    "Using only **weight** gives a limited model. Let's use **all numeric features** to predict mpg.\n",
    "\n",
    "**Tasks:**\n",
    "1. Reload the dataset and drop the `name` column and missing values (the cleanup cell is provided).\n",
    "2. Separate the target **mpg** from the remaining features.\n",
    "3. Standardize **all** features using a single `StandardScaler`.\n",
    "4. Fit a `sklearn.linear_model.SGDRegressor` with `eta0=0.001` and `max_iter=10000`.\n",
    "5. Compute the $R^2$ on the full dataset. How does it compare to the single-feature model?\n",
    "6. Print `model.coef_` alongside the feature names. Which feature has the largest absolute coefficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Reload and clean\n",
    "dataset = pd.read_csv(url).drop(columns=['name']).dropna()\n",
    "origin_map = {'usa': 1, 'europe': 2, 'japan': 3}\n",
    "dataset['origin'] = dataset['origin'].map(origin_map)\n",
    "\n",
    "# Separate features and target\n",
    "# YOUR CODE HERE\n",
    "target = ...\n",
    "features = ...\n",
    "\n",
    "# Standardize features\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Fit SGDRegressor\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Print R-squared\n",
    "\n",
    "# Print coefficients with feature names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1e12c",
   "metadata": {},
   "source": [
    "*Which feature has the largest coefficient and what does this mean?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7769bb4a",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 10 — Train/Test Split\n",
    "\n",
    "So far we evaluated the model on the **same data** it was trained on. This is problematic — the model might just memorize the training data without learning the true underlying relationship. This is called **overfitting**.\n",
    "\n",
    "To get an honest estimate of model performance, we split the data into:\n",
    "- A **training set** (used to fit the model)\n",
    "- A **test set** (used to evaluate on unseen data)\n",
    "\n",
    "**Tasks:**\n",
    "1. Use `sklearn.model_selection.train_test_split` to split the standardized features and target into 80% training / 20% test (use `random_state=42`).\n",
    "2. Fit an `SGDRegressor` on the **training** data only.\n",
    "3. Compute $R^2$ on the **training** set and on the **test** set.\n",
    "4. Is there a difference? What does this tell you about the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Split the data\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 2. Fit the model on the training set\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 3. Evaluate on both sets\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1e6f5",
   "metadata": {},
   "source": [
    "*Is there a difference between training and test $R^2$? What does this tell you?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025778ff",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 11 — Predict for a New Car\n",
    "\n",
    "Suppose a new car has the following specifications:\n",
    "\n",
    "| cylinders | displacement | horsepower | weight | acceleration | model_year | origin |\n",
    "|-----------|-------------|------------|--------|--------------|------------|--------|\n",
    "| 4 | 120 | 80 | 2500 | 15.5 | 82 | 3 (Japan) |\n",
    "\n",
    "**Tasks:**\n",
    "1. Create a DataFrame (or array) with this car's features.\n",
    "2. Standardize the features using the **same scaler** you fitted on the training data.\n",
    "3. Use your trained model to predict the mpg for this car.\n",
    "4. Why is it crucial to use the same scaler from the training data, rather than fitting a new one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b91d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "new_car = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb4b5e",
   "metadata": {},
   "source": [
    "*Why must we use the same scaler?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5559289",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus Exercise — Residual Analysis\n",
    "\n",
    "A **residual plot** helps diagnose whether a linear model is appropriate for the data.\n",
    "\n",
    "**Tasks:**\n",
    "1. Using your multi-feature model from Exercise 10, compute the predictions on the **test** set.\n",
    "2. Compute the residuals: `residuals = y_test - predictions`.\n",
    "3. Create a scatter plot of predictions (x-axis) vs residuals (y-axis).\n",
    "4. Add a horizontal dashed line at $y = 0$.\n",
    "5. If the model is appropriate, what pattern should you see? What pattern would indicate a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1297daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e9dd9",
   "metadata": {},
   "source": [
    "*Describe the pattern you observe and what it tells you about the linear model.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
