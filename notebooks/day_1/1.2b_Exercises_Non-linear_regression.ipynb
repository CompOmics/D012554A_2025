{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb222ee3",
   "metadata": {},
   "source": [
    "# 1.2 Exercises – Non-linear Regression\n",
    "\n",
    "In this notebook you will practice the non-linear regression techniques from the lecture using a **new dataset**.\n",
    "\n",
    "## Dataset: Diamond Prices\n",
    "\n",
    "We will use the [diamonds dataset](https://ggplot2.tidyverse.org/reference/diamonds.html), which contains prices and attributes of ~54,000 diamonds. For efficiency we work with a random sample of **500 diamonds**.\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| `carat` | Weight of the diamond (0.2–5.01) |\n",
    "| `price` | Price in US dollars ($326–$18,823) |\n",
    "\n",
    "The relationship between `carat` and `price` is clearly **non-linear** — larger diamonds are disproportionately more expensive.\n",
    "\n",
    "**Goal**: Use polynomial regression and other non-linear techniques to model diamond prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1e04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b95cb",
   "metadata": {},
   "source": [
    "## Exercise 1 – Load and explore the dataset\n",
    "\n",
    "Load the diamonds dataset from the URL below and take a random sample of 500 rows (use `random_state=42`). Keep only the `carat` and `price` columns.\n",
    "\n",
    "Display the shape, basic statistics (`.describe()`), and the first 5 rows.\n",
    "\n",
    "```python\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/diamonds.csv\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b33ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/diamonds.csv\"\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab6e6f1",
   "metadata": {},
   "source": [
    "## Exercise 2 – Visualize the relationship\n",
    "\n",
    "Create a scatter plot of `carat` (x-axis) versus `price` (y-axis) using `sns.lmplot` with `fit_reg=False`.\n",
    "\n",
    "Does the relationship look linear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c044898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3af41a8",
   "metadata": {},
   "source": [
    "## Exercise 3 – Fit a linear model\n",
    "\n",
    "Fit a `LinearRegression` model using `carat` as the single feature to predict `price`.\n",
    "\n",
    "1. Compute and print the R² score.\n",
    "2. Plot the data points and overlay the linear fit line.\n",
    "\n",
    "**Hint**: Use `np.linspace` to generate evenly spaced x-values for plotting the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9197143",
   "metadata": {},
   "source": [
    "## Exercise 4 – Evaluate the linear model\n",
    "\n",
    "Is the linear model a good fit for this data? Why or why not? Write your answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16521d24",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582d19cc",
   "metadata": {},
   "source": [
    "## Exercise 5 – Polynomial model (degree 2)\n",
    "\n",
    "Add a new feature `carat^2` (the square of `carat`) to the dataset. Fit a `LinearRegression` model using both `carat` and `carat^2` as features.\n",
    "\n",
    "1. Print the R² score and compare it to the linear model.\n",
    "2. Plot the data and overlay the degree-2 polynomial curve.\n",
    "\n",
    "**Hint**: To plot the curve, compute predictions as:\n",
    "\n",
    "$$\\hat{y} = \\theta_0 + \\theta_1 \\cdot x + \\theta_2 \\cdot x^2$$\n",
    "\n",
    "where the coefficients come from `model.intercept_` and `model.coef_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec656a",
   "metadata": {},
   "source": [
    "## Exercise 6 – Higher-degree polynomials with scaling\n",
    "\n",
    "Fit polynomial models of degrees 2 through 7 and plot all fits on a single figure.\n",
    "\n",
    "**Important**: Higher-degree polynomial features (e.g. `carat^7`) can have very large values. Use `MinMaxScaler` to scale each polynomial feature to the [0, 1] range before fitting.\n",
    "\n",
    "**Steps**:\n",
    "1. Loop over degrees 2 to 7.\n",
    "2. For each degree, build a feature matrix with columns `carat`, `carat^2`, ..., `carat^d`.\n",
    "3. Scale the polynomial features (degree ≥ 2) using `MinMaxScaler`.\n",
    "4. Fit a `LinearRegression` and store the R² score.\n",
    "5. Generate predictions for plotting (remember to scale the plot features with the **same** scaler).\n",
    "6. Show all polynomial fits on one scatter plot with a legend that includes the R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b97c19",
   "metadata": {},
   "source": [
    "## Exercise 7 – Train/test split: detecting overfitting\n",
    "\n",
    "Split the data into 80% training and 20% test sets (use `random_state=42`). For each polynomial degree from 2 to 9:\n",
    "\n",
    "1. Build polynomial features and scale them with `MinMaxScaler`.\n",
    "2. Fit on the **training** set.\n",
    "3. Compute R² on both the training and test sets.\n",
    "\n",
    "Print a table showing degree, training R², and test R².\n",
    "\n",
    "**Hint**: Use `train_test_split` from `sklearn.model_selection`. Make sure to `fit` the scaler on the training data only and `transform` both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224ee034",
   "metadata": {},
   "source": [
    "## Exercise 8 – Interpret the results\n",
    "\n",
    "Based on the training vs. test R² values:\n",
    "- Which polynomial degree gives the best **test** performance?\n",
    "- At what degree do you start to see signs of **overfitting** (training R² much higher than test R²)?\n",
    "\n",
    "Write your answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4661a3d",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde6de55",
   "metadata": {},
   "source": [
    "## Exercise 9 – Using `PolynomialFeatures`\n",
    "\n",
    "Instead of manually creating polynomial features, use `sklearn.preprocessing.PolynomialFeatures` to automatically generate them.\n",
    "\n",
    "1. Create degree-3 polynomial features from `carat` (set `include_bias=False`).\n",
    "2. Fit a `LinearRegression` model on these features.\n",
    "3. Print the R² score.\n",
    "4. Compare this result with your manual degree-3 polynomial from Exercise 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7d9511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24156e",
   "metadata": {},
   "source": [
    "## Exercise 10 – Sigmoid curve fitting\n",
    "\n",
    "As discussed in the lecture, many biological relationships follow a **sigmoid (logistic) function**:\n",
    "\n",
    "$$f(x) = \\frac{L}{1 + e^{-\\theta_1(x - \\theta_0)}}$$\n",
    "\n",
    "where:\n",
    "- $L$ is the curve's maximum value\n",
    "- $\\theta_0$ is the x-value of the sigmoid's midpoint\n",
    "- $\\theta_1$ controls the steepness\n",
    "\n",
    "The cell below provides synthetic dose-response data. Your task:\n",
    "\n",
    "1. Define a Python function `sigmoid(x, L, theta0, theta1)` implementing the formula above.\n",
    "2. Fit the parameters using `scipy.optimize.curve_fit`.\n",
    "3. Plot the data and the fitted sigmoid curve.\n",
    "4. Print the fitted parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221a7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic dose-response data (provided)\n",
    "np.random.seed(42)\n",
    "dose = np.linspace(0, 10, 30)\n",
    "response = 100 / (1 + np.exp(-(1.5 * (dose - 5)))) + np.random.normal(0, 3, size=30)\n",
    "response = np.clip(response, 0, 100)\n",
    "dose_response = pd.DataFrame({'dose': dose, 'response': response})\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.scatter(dose_response['dose'], dose_response['response'], s=60)\n",
    "plt.xlabel('Dose')\n",
    "plt.ylabel('Response (%)')\n",
    "plt.title('Dose-Response Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b79bdbb",
   "metadata": {},
   "source": [
    "## Bonus – Log-transform the target variable\n",
    "\n",
    "Sometimes a non-linear relationship can be made approximately linear by **transforming the target variable**.\n",
    "\n",
    "1. Create `log_price = log(price)` using `np.log`.\n",
    "2. Fit a simple `LinearRegression` model: `carat` → `log_price`.\n",
    "3. Compute R² and plot the fit.\n",
    "4. Compare this R² to your polynomial models.\n",
    "\n",
    "**Why does this work?** If price ≈ $e^{a + b \\cdot \\text{carat}}$, then $\\log(\\text{price}) \\approx a + b \\cdot \\text{carat}$, which is linear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa20ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
